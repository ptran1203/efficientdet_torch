lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)
lrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)
momentum: 0.937  # SGD momentum/Adam beta1
weight_decay: 0.0005  # optimizer weight decay 5e-4
warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.1  # warmup initial bias lr
box: 0.05  # box loss gain
cls: 0.5  # cls loss gain
cls_pw: 1.0  # cls BCELoss positive_weight
obj: 1.0  # obj loss gain (scale with pixels)
obj_pw: 1.0  # obj BCELoss positive_weight
iou_t: 0.20  # IoU training threshold

# Path
weight_dir: /content/drive/MyDrive/efficientdet/weights
fold_csv: /content/train_record/train/fold.csv
data_csv: /content/train_record/train/train_df.csv
image_dir: /content/train_record/train
weight_dir: /content/drive/MyDrive/efficientdet/weights

# Training config
batch_size: 4
image_size: 640
phi: 4 # effdetD{phi}
num_classes: 14
lr: 0.001
warmup_epochs: 3

# Augmentations
shift_limit: 0.0625
scale_limit: 0.1
rot_limit: 45
gamma_limit_min: 80
gamma_limit_max: 120
mixup: 0.0
mosaic: 1.0
flipud: 0.0
fliplr: 0.5
shear: 0.0
translate: 0.1
random_intensity: 0